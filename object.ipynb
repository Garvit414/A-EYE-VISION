{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  1] [[149  95 167 145]\n",
      " [149  95 167 145]]\n",
      "[ 1 41  1] [[130  91 188 149]\n",
      " [191 117 129 122]\n",
      " [135   0 184 239]]\n",
      "[1] [[269 161 369 318]]\n",
      "[1 1] [[274 165 364 310]\n",
      " [358 200 282 210]]\n",
      "[ 1 33] [[278 119 360 354]\n",
      " [ 49 108 149 125]]\n",
      "[ 1  1 33 77 33] [[293  88 345 350]\n",
      " [289 165 343 202]\n",
      " [ 52  99 152 123]\n",
      " [392 336 164 103]\n",
      " [403 340 164 100]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "thres = 0.45 # Threshold to detect object\n",
    "\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# ESP32 URL\n",
    "URL = \"http://192.168.137.86\"\n",
    "AWB = True\n",
    "\n",
    "# Face recognition and opencv setup\n",
    "cap = cv2.VideoCapture(URL + \":81/stream\")\n",
    "\n",
    "\n",
    "def set_resolution(url: str, index: int=1, verbose: bool=False):\n",
    "    try:\n",
    "        if verbose:\n",
    "            resolutions = \"10: UXGA(1600x1200)\\n9: SXGA(1280x1024)\\n8: XGA(1024x768)\\n7: SVGA(800x600)\\n6: VGA(640x480)\\n5: CIF(400x296)\\n4: QVGA(320x240)\\n3: HQVGA(240x176)\\n0: QQVGA(160x120)\"\n",
    "            print(\"available resolutions\\n{}\".format(resolutions))\n",
    "\n",
    "        if index in [10, 9, 8, 7, 6, 5, 4, 3, 0]:\n",
    "            requests.get(url + \"/control?var=framesize&val={}\".format(index))\n",
    "        else:\n",
    "            print(\"Wrong index\")\n",
    "    except:\n",
    "        print(\"SET_RESOLUTION: something went wrong\")\n",
    "\n",
    "def set_quality(url: str, value: int=1, verbose: bool=False):\n",
    "    try:\n",
    "        if value >= 10 and value <=63:\n",
    "            requests.get(url + \"/control?var=quality&val={}\".format(value))\n",
    "    except:\n",
    "        print(\"SET_QUALITY: something went wrong\")\n",
    "\n",
    "def set_awb(url: str, awb: int=1):\n",
    "    try:\n",
    "        awb = not awb\n",
    "        requests.get(url + \"/control?var=awb&val={}\".format(1 if awb else 0))\n",
    "    except:\n",
    "        print(\"SET_QUALITY: something went wrong\")\n",
    "    return awb\n",
    "\n",
    "if __name__ == '__main__':\n",
    "         set_resolution(URL, index=8)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3,640)\n",
    "# cap.set(4,480)\n",
    "# cap.set(10,70)\n",
    "\n",
    "classNames= [ ]\n",
    "classFile = \"coco.names\"\n",
    "with open(classFile,\"rt\") as f:\n",
    "    classNames = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "configPath = \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "weightsPath = \"frozen_inference_graph.pb\"\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "while True:\n",
    "    if cap.isOpened():\n",
    "            ret, img = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.equalizeHist(gray)\n",
    "    if ((cv2.waitKey(0)) == ord('q')):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        \n",
    "        ret,img = cap.read()\n",
    "        classIds, confs, bbox = net.detect (img, confThreshold=thres)\n",
    "        print(classIds,bbox)\n",
    "        # key = cv2. waitKey(1)\n",
    "        if len (classIds) != 0 :\n",
    "            for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "                cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "                cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "                engine.say(\"a\"+str(classNames[classId - 1]) + \"is in front of you\")\n",
    "                engine.runAndWait()\n",
    "                cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "                break\n",
    "\n",
    "    cv2.imshow('A-EYE  Vision', img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
